#include<iostream>
#include<vector>
#include<queue>
#include<stack>
#include<omp.h>

using namespace std;

class Graph{
    public:
    int vertices;
    vector<vector<int>> adj;
    
    Graph(int vertices){
        this->vertices = vertices;
        adj.resize(vertices);
    }
    
    void addEdge(int src, int dest){
        adj[src].push_back(dest);
        adj[dest].push_back(src);
    }
    
    void BFS(int start){
        vector<bool> visited(vertices, false);
        queue<int> q;
        
        visited[start] = true;
        q.push(start);
        
        while(!q.empty()){
            int currVertex = q.front();
            q.pop();
            cout << currVertex << " ";
            
            #pragma omp parallel for
            for(int i = 0; i < adj[currVertex].size(); i++){
                int neighbor = adj[currVertex][i];
                #pragma omp critical
                if(!visited[neighbor]){
                    visited[neighbor] = true;
                    q.push(neighbor);
                }
            }
        }
        cout << endl;
    }
    
    void DFS(int start){
        vector<bool> visited(vertices, false);
        stack<int> s;
        
        visited[start] = true;
        s.push(start);
        
        while(!s.empty()){
            int currVertex = s.top();
            s.pop();
            cout << currVertex << " ";
            
            #pragma omp parallel for
            for(int i = 0; i < adj[currVertex].size(); i++){
                int neighbor = adj[currVertex][i];
                
                if(!visited[neighbor]){
                    visited[neighbor] = true;
                    s.push(neighbor);
                }
            }
        }
        cout << endl ;
    }
};

int main(){
    int n;
    cout << "Enter the no of vertices :- ";
    cin >> n;
    
    Graph graph(n);
    
    int edge;
    cout << "Enter the no of edges :- ";
    cin >> edge;
    
    cout << "Enter the edges (src and dest) " << endl;
    for(int i = 0; i < edge; i++){
        int src, dest;
        cin >> src >> dest;
        graph.addEdge(src, dest);
    }
    
    int start;
    cout << "Enter the starting node :- ";
    cin >> start;
    graph.BFS(start);
    graph.DFS(start);
}



-------------------------------------------------------------------------------------------------------------------



#include<iostream>
#include<ctime>
#include<cstdlib>
#include<omp.h>

using namespace std;

void bubbleSort(int arr[], int size){
    for(int i = 0; i < size; i++){
        for(int j = 0; j < size - i -1; j++){
            if(arr[j] > arr[j+1]){
                int temp = arr[j];
                arr[j] = arr[j+1];
                arr[j+1] = temp;
            }
        }
    }
}

void merge(int arr[], int l, int m, int r){
    int n1 = m -l + 1;
    int n2 = r - m;
    
    int *L = new int[n1];
    int *R = new int[n2];
    
    for(int i = 0; i < n1; i++){
        L[i] = arr[l + i];
    }
    for(int j = 0; j < n2; j++){
        R[j] = arr[m + 1 + j];
    }
    
    int i = 0, j = 0, k = 1;
    
    while(i < n1 && j < n2){
        if(L[i] <= R[j]){
            arr[k++] = L[i++];
        } else {
            arr[k++] = R[j++];
        }
    }
    
    while(i < n1){
        arr[k++] = L[i++];
    }
    while(j < n2){
        arr[k++] = R[j++];
    }
    
    delete []L;
    delete []R;
}

void mergeSort(int arr[],int l, int r){
    if(l < r){
        int m = l + (r -l) / 2;
        
        #pragma omp parallel
        {
            #pragma omp section
            {
                mergeSort(arr, l, m);
            }
            #pragma omp section
            {
                mergeSort(arr, m+1, r);
            }
        }
        
        merge(arr, l, m, r);
    }
}


int main(){
    int n;
    cout << "Enter the size of array :- ";
    cin >> n;
    
    int *arr = new int[n];
    int *arr1 = new int[n];
    
    srand(time(0));
    for(int i = 0; i < n; i++){
        arr[i] = rand() % 100;
        arr1[i] = rand() % 100;
    }
    
    clock_t start = clock();
    bubbleSort(arr, n);
    clock_t end = clock();
    double sbt = double (end - start) / CLOCKS_PER_SEC;
    
    start = clock();
    #pragma omp parallel 
    {
        bubbleSort(arr1, n);
    }
    end = clock();
    double pbt = double (end - start) / CLOCKS_PER_SEC;
    
    start = clock();
    mergeSort(arr, 0, n-1);
    end = clock();
    double smt = double (end - start) / CLOCKS_PER_SEC;
    
    start = clock();
    #pragma omp parallel 
    {
        #pragma omp single
        {
            mergeSort(arr, 0, n-1);       
        }
    }
    end = clock();
    double pmt = double (end - start) / CLOCKS_PER_SEC;
    
    cout << sbt << endl;
    cout << pbt << endl;
    cout << smt << endl;
    cout << pmt << endl;
    
}


--------------------------------------------------------------------------------------------------------------------

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
import matplotlib.pyplot as plt

# Load Boston Housing dataset
(x_train, y_train), (x_test, y_test) = keras.datasets.boston_housing.load_data()

print("Training samples:", x_train.shape)
print("Testing samples:", x_test.shape)


# Compute mean and std on training set
mean = x_train.mean(axis=0)
std = x_train.std(axis=0)

# Normalize both train and test data
x_train = (x_train - mean) / std
x_test = (x_test - mean) / std


model = keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=(x_train.shape[1],)),
    layers.Dense(64, activation='relu'),
    layers.Dense(1)  # Only one output for price
])


model.compile(
    optimizer='adam',
    loss='mse',
    metrics=['mae']
)


history = model.fit(
    x_train, y_train,
    epochs=100,
    batch_size=32,
    validation_split=0.2,
    verbose=1
)


loss, mae = model.evaluate(x_test, y_test, verbose=2)
print(f"Test MAE: {mae:.2f}")


# Plot training and validation loss
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss During Training')
plt.xlabel('Epoch')
plt.ylabel('MSE')
plt.legend()
plt.show()

# Plot MAE
plt.plot(history.history['mae'], label='Train MAE')
plt.plot(history.history['val_mae'], label='Validation MAE')
plt.title('MAE During Training')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend()
plt.show()


-----------------------------------------------------------------------------------------------------------------------




import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt

# Load dataset (only keep top 10,000 most frequent words)
num_words = 10000

(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=num_words)

print(f"Training samples: {len(x_train)}")
print(f"Testing samples: {len(x_test)}")


# Set maximum review length
maxlen = 256

# Pad sequences with zeros
x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)
x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)


model = keras.Sequential([
    layers.Embedding(num_words, 32, input_length=maxlen),  # Embedding layer
    layers.Flatten(),  # Flatten the 2D embedding to 1D
    layers.Dense(64, activation='relu'),
    layers.Dense(32, activation='relu'),
    layers.Dense(1, activation='sigmoid')  # Output layer: binary classification
])


model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=['accuracy']
)


history = model.fit(
    x_train, y_train,
    epochs=10,
    batch_size=512,
    validation_split=0.2,
    verbose=1
)


loss, accuracy = model.evaluate(x_test, y_test, verbose=2)
print(f"\nTest Accuracy: {accuracy:.2f}")


plt.figure(figsize=(10,5))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Accuracy During Training')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

plt.figure(figsize=(10,5))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Loss During Training')
plt.xlabel('Epochs')
plt.ylabel('Binary Crossentropy Loss')
plt.legend()
plt.grid(True)
plt.show()


--------------------------------------------------------------------------------------------------------


